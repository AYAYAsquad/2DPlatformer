Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,4.9555435,-0.10689266,120.61728395061728,-1.0617283950617284,-1.0617283950617284,0.093626246,0.06763044,0.00029996876,1.0
20000,4.9289284,-0.3394271,141.37142857142857,-1.0571428571428572,-1.0571428571428572,0.041818075,0.06582041,0.00029991256,1.0
30000,4.903092,-0.44982424,118.45238095238095,-1.0952380952380953,-1.0952380952380953,0.046686538,0.0623196,0.00029985,1.0
40000,4.888334,-0.5636946,124.2,-1.1,-1.1,0.036845483,0.06914421,0.00029978782,1.0
50000,4.896124,-0.62407833,125.76315789473684,-1.0789473684210527,-1.0789473684210527,0.025441691,0.06528546,0.00029972548,1.0
